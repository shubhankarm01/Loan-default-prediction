{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### For connecting and retrieving query results from MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "class mysqlconnector:\n",
    "    \n",
    "    def __init__(self, database = 'test'):\n",
    "        try:\n",
    "            connection = mysql.connector.connect(host = 'localhost',\n",
    "                                                user = 'root',\n",
    "                                                password = '',\n",
    "                                                use_pure = True,\n",
    "                                                database = database\n",
    "                                                )\n",
    "            if connection.is_connected:\n",
    "                db_info = connection.get_server_info()\n",
    "                print('connected to MYSQL server version', db_info)\n",
    "                print('You are connected to the database:', database)\n",
    "                self.connection = connection\n",
    "        except Exception as e:\n",
    "            print('Error while connecting to MYSQL', e)\n",
    "            \n",
    "    def execute(self, query, header = False):\n",
    "        cursor = self.connection.cursor(buffered = True)\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        try:\n",
    "            record = cursor.fetchall()\n",
    "            if header:\n",
    "                header = [i[0] for i in cursor.description]\n",
    "                return {'header': header, 'record': record}\n",
    "            else:\n",
    "                return record\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def to_df(self, query):\n",
    "        result = self.execute(query, header = True)\n",
    "        df = pd.DataFrame(result['record'])\n",
    "        df.columns = result['header']\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mysqlconnector('bank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM Loan JOIN Account USING(account_id);'\n",
    "df = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_good for food loans\n",
    "df_good = df[df['status'].isin(['A','C'])]\n",
    "df_good.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bad for bad loans\n",
    "df_bad = df[df['status'].isin(['B', 'D'])]\n",
    "df_bad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To plot histogram of the loan amount\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,5))\n",
    "df_good['amount'].hist(bins = 25, ax = ax1, label = 'good loans', color = 'grey')\n",
    "df_bad['amount'].hist(bins =  25, ax = ax2, label = 'bad loans', color = 'red')\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot histogram of the loan duration\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,5))\n",
    "df_good['duration'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df_bad['duration'].hist(ax = ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend(loc = 9)\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot histogram of the loan monthly installment\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,5))\n",
    "df_good['payments'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df_bad['payments'].hist(ax = ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot histogram of the loan location\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,5))\n",
    "df_good['district_id'].hist(ax = ax1, label = 'good_loan', color = 'grey', bins = 25)\n",
    "df_bad['district_id'].hist(ax = ax2, label = 'bad_loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To rename columns date column in Loan and Account tables\n",
    "\n",
    "# No need to run rename commands as the columns name have been changed in the database\n",
    "\n",
    "query = \"\"\"ALTER TABLE Loan \n",
    "        CHANGE COLUMN `date` Loan_date DATE;\"\"\"\n",
    "\n",
    "df1 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM Loan;'\n",
    "\n",
    "df1 = db.to_df(query)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'ALTER TABLE Account CHANGE COLUMN `date` Account_date DATE;'\n",
    "db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM Loan JOIN Account USING(account_id)'\n",
    "df = db.to_df(query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "# df1.rename(columns = {'date': 'loan_dates'})\n",
    "df1.columns.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature creation from date of account opening and date of applying loan (DID : Dfference In Dates)\n",
    "\n",
    "df['DID'] = df['Loan_date'] - df['Account_date']\n",
    "df_good = df[df['status'].isin(['A', 'C'])]\n",
    "df_bad = df[df['status'].isin(['B', 'D'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts timedelta64 to float64 as timedelta was not being able to use for plotting histogram\n",
    "df_good['DID'].astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way of converting the timedelta64 to the int64 for plotting histogram\n",
    "df_good['DID'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the histogram of the time difference between opening the account and the taking the loan\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "df_good['DID'].astype('timedelta64[D]').hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df_bad['DID'].astype('timedelta64[D]').hist(ax = ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining district along with the loan and account tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT * FROM Loan JOIN Account USING(account_id) JOIN District USING(district_id)\"\"\"\n",
    "\n",
    "df1 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns = {'A4': 'No_inhabitants', 'A11': 'Average_salary', 'A14': 'No_entrepreneur_per1000'})\n",
    "\n",
    "df1['Average_unemployment_rate'] = df1[['A12', 'A13']].mean(axis = 1)\n",
    "df1['Average_crime_rate'] = df1[['A15', 'A16']].mean(axis = 1)/df1['No_inhabitants']\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_good = df1[df1['status'].isin(['A', 'C'])]\n",
    "df1_bad = df1[df1['status'].isin(['B', 'D'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograme plot for Number of inhabitants\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize = (15,5))\n",
    "\n",
    "df1_good['No_inhabitants'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df1_bad['No_inhabitants'].hist(ax = ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot for average salary\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,5))\n",
    "df1_good['Average_salary'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df1_bad['Average_salary'].hist(ax = ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram to plot for average unemployment rate \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,5))\n",
    "df1_good['Average_unemployment_rate'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df1_bad['Average_unemployment_rate'].hist(ax = ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Average_unemployment_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for average crime rate\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,5))\n",
    "\n",
    "df1_good['Average_crime_rate'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df1_bad['Average_crime_rate'].hist(ax = ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching order tabel with loan table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM Loan;'\n",
    "\n",
    "df2 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT account_id, amount Order_amount\n",
    "        FROM `Order`\n",
    "        WHERE account_id in (SELECT account_id FROM Loan);\n",
    "        \"\"\"\n",
    "\n",
    "df3 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype of Order_amount was 'Object' before changing it to 'float'\n",
    "\n",
    "df3['Order_amount'] = df3['Order_amount'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.groupby('account_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df2.set_index('account_id').join(df3.groupby('account_id').mean())\n",
    "df4.head()\n",
    "\n",
    "# or use pd.merge(df2, df3.groupby('account_id').mean(), on = 'account_id', how = 'outer').set_index('account_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.rename(columns = {'Order_amount': 'Average order_amount'})\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_good = df4[df4['status'].isin(['A', 'C'])]\n",
    "df4_bad = df4[df4['status'].isin(['B', 'D'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram plot for average order amount\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,5))\n",
    "df4_good['Average order_amount'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df4_bad['Average order_amount'].hist(ax= ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining loan table with transaction table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT * \n",
    "        FROM Loan;\"\"\"\n",
    "\n",
    "df5 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT account_id, amount Trans_amount, balance Trans_balance\n",
    "        FROM Trans WHERE account_id IN (SELECT account_id FROM Loan);\n",
    "        \"\"\"\n",
    "\n",
    "df6 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_transaction = df6.groupby('account_id').count().iloc[:,1]\n",
    "No_transaction.name = 'No_transaction'\n",
    "No_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df6.groupby('account_id').mean()\n",
    "df6.columns = ['Average_trans_amount', 'Average_trans_balance']\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df5.set_index('account_id').join(df6).join(No_transaction)\n",
    "df7.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df5.shape, df6.shape, No_transaction.shape, df7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7_good = df7[df7['status'].isin(['A', 'C'])]\n",
    "df7_bad = df7[df7['status'].isin(['B', 'D'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot for average transaction amount\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "df7_good['Average_trans_amount'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df7_bad['Average_trans_amount'].hist(ax = ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot for average balance after transaction\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "df7_good['Average_trans_balance'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df7_bad['Average_trans_balance'].hist(ax = ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for number of transaction\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "df7_good['No_transaction'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df7_bad['No_transaction'].hist(ax = ax2, label = 'bad loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Loan tabel with Credit card tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT account_id, card_id, Card.type Card_type, status\n",
    "        FROM Loan JOIN Desposition USING(account_id) LEFT JOIN Card USING(disp_id)\n",
    "        \"\"\"\n",
    "\n",
    "# JOIN operation with USING gives only those rows in which the column mention in the USING matches.\n",
    "\n",
    "df8 = db.to_df(query)\n",
    "df8.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8_card = df8[~df8['card_id'].isna()]\n",
    "\n",
    "# FROM Loan JOIN Desposition USING(account_id) JOIN Card USING(disp_id); can also be used but it was not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"\n",
    "#         SELECT account_id, card_id, Card.type Card_type, status\n",
    "#         FROM Loan JOIN Desposition USING(account_id) JOIN Card USING(disp_id);\n",
    "#         \"\"\"\n",
    "\n",
    "# df9 = db.to_df(query)\n",
    "# df9.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8_good = df8[df8['status'].isin(['A', 'C'])]\n",
    "df8_bad = df8[df8['status'].isin(['B', 'D'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barchart for credit card type\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5)) \n",
    "\n",
    "df8_good[['Card_type', 'account_id']].groupby('Card_type', dropna = False).count().plot.bar(ax = ax1, color = 'grey', label = 'good loan', legend = False)\n",
    "df8_bad[['Card_type', 'account_id']].groupby('Card_type', dropna = False).count().plot.bar(ax = ax2, color = 'red', label = 'bad loan', legend = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combing Account table and Client Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking aprrox. 6 mins to run\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * \n",
    "        FROM Loan JOIN Desposition USING(account_id) \n",
    "        JOIN Client USING(Client_id) \n",
    "        JOIN District USING(district_id);\n",
    "        \"\"\"\n",
    "df9 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "         SELECT account_id, district_id Acc_dist_id\n",
    "         FROM Loan JOIN Account USING(account_id);\n",
    "         \"\"\"\n",
    "\n",
    "df10 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df9.set_index('account_id').join(df10.set_index('account_id'))\n",
    "\n",
    "# or\n",
    "# df12 = pd.merge(df9, df10, on = 'account_id', how = 'inner').set_index('account_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df11[df11['type'] == 'OWNER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df11.shape, df11.index.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11['Same_district'] = df11['district_id'] == df11['Acc_dist_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11['Loan_date'] = df11['Loan_date'].astype('datetime64')\n",
    "df11['birth_date'] = df11['birth_date'].astype('datetime64')\n",
    "df11['Owner_age'] = df11['Loan_date'] - df11['birth_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11['Owner_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert days value of timedelta64 type into year values of float64 type\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df11['Owner_age'] = df11['Owner_age']/np.timedelta64(1, 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df11.reset_index()\n",
    "df11_good = df11[df11['status'].isin(['A', 'C'])]\n",
    "df11_bad = df11[df11['status'].isin(['B', 'D'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11_good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart for client district and account district\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "df11_good[['account_id', 'Same_district']].groupby('Same_district').count().plot.bar(ax = ax1, color = 'grey', legend = False)\n",
    "df11_bad[['account_id', 'Same_district']].groupby('Same_district').count().plot.bar(ax = ax2, color = 'red', legend = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barchart for gender\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "df11_good[['gender', 'account_id']].groupby('gender').count().plot.bar(ax = ax1, color = 'grey', legend = False)\n",
    "df11_bad[['gender', 'account_id']].groupby('gender').count().plot.bar(ax= ax2, color = 'red', legend = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram for owner age\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "\n",
    "df11_good['Owner_age'].hist(ax = ax1, label = 'good loan', color = 'grey', bins = 25)\n",
    "df11_bad['Owner_age'].hist(ax = ax2, label = 'bad_loan', color = 'red', bins = 25)\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Finalizing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT account_id, amount, duration, payments, Loan_date, status, Account_date, A4, A11, A12, A13, A14, A15, A16\n",
    "        FROM Loan JOIN Account USING(account_id) JOIN District USING(district_id)\n",
    "        \"\"\"\n",
    "\n",
    "df = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('account_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DID'] = (df['Loan_date'] - df['Account_date']).dt.days\n",
    "df = df.rename(columns = {'A4': 'No_inhabitants', 'A11': 'Average_salary'})\n",
    "df['Average_unemployment_rate'] = df[['A12', 'A13']].mean(axis = 1)\n",
    "df['Average_crime_rate'] = df[['A15', 'A16']].mean(axis = 1)/df['No_inhabitants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT account_id, amount Order_amount\n",
    "        FROM `Order`\n",
    "        WHERE account_id IN(SELECT account_id FROM Loan);\n",
    "        \"\"\"\n",
    "\n",
    "df2 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Order_amount'] = df2['Order_amount'].astype('float')\n",
    "df = df.join(df2.groupby('account_id').mean())\n",
    "df = df.rename(columns = {'Order_amount': 'Average_order_amount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT account_id, amount Trans_amount, balance Trans_balance\n",
    "        FROM Trans\n",
    "        WHERE account_id IN (SELECT account_id FROM Loan);\n",
    "        \"\"\"\n",
    "\n",
    "df3 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_transaction = df3.groupby('account_id').count().iloc[: , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_transaction.name = 'No_transaction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.groupby('account_id').mean()\n",
    "df3.columns = ['Average_trans_amount', 'Average_trans_balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df3).join(No_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT account_id, Card.type Card_type\n",
    "        FROM Loan JOIN Desposition USING(account_id) LEFT JOIN Card USING(disp_id)\n",
    "        WHERE Desposition.type = 'OWNER';\n",
    "        \"\"\"\n",
    "\n",
    "df4 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df4.set_index('account_id'), how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Card_type'].fillna('No', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT account_id, Loan_date, Account.district_id Account_dist_id, Client.district_id Client_dist_id, gender, birth_date\n",
    "        FROM Loan JOIN Account USING(account_id) JOIN Desposition USING(account_id) JOIN Client USING(Client_id) WHERE Desposition.type = 'Owner';\n",
    "        \"\"\"\n",
    "\n",
    "df5 = db.to_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['Same_district'] = df5['Account_dist_id'] == df5['Client_dist_id']\n",
    "df5['Owner_age'] = (df5['Loan_date'] - df5['birth_date']).astype('timedelta64[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df5.set_index('account_id')[['Same_district', 'gender', 'Owner_age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Default'] = df['status'].isin(['A', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['amount', 'duration', 'payments', 'DID', 'Average_order_amount',\n",
    "         'Average_trans_amount', 'Average_trans_balance', 'No_transaction', \n",
    "         'Card_type', 'No_inhabitants', 'Average_salary', 'Average_unemployment_rate', \n",
    "         'Average_crime_rate', 'gender', 'Owner_age', 'Same_district', 'Default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(df.corr(), cmap = 'RdYlGn', annot = True, annot_kws = {'fontsize': 7.5}, linewidths = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(i , df[i].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payments'] = df['payments'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To seperate numerical and categorical data\n",
    "\n",
    "cat_columns = []\n",
    "num_columns = []\n",
    "bool_columns = []\n",
    "\n",
    "for i in df2.columns:\n",
    "    if df2[i].dtype == 'object':\n",
    "        cat_columns.append(i)\n",
    "    else:\n",
    "        if df2[i].dtype =='bool':\n",
    "            bool_columns.append(i)\n",
    "        else:\n",
    "            num_columns.append(i)\n",
    "        \n",
    "print(cat_columns,'\\n\\n', num_columns, '\\n\\n', bool_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[:,-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To seperate numerical and categorical data\n",
    "\n",
    "cat_columns = []\n",
    "num_columns = []\n",
    "bool_columns = []\n",
    "\n",
    "for i in df3.columns:\n",
    "    if df3[i].dtype == 'object':\n",
    "        cat_columns.append(i)\n",
    "    else:\n",
    "        if df3[i].dtype =='bool':\n",
    "            bool_columns.append(i)\n",
    "        else:\n",
    "            num_columns.append(i)\n",
    "        \n",
    "print(cat_columns,'\\n\\n', num_columns, '\\n\\n', bool_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE = OneHotEncoder()\n",
    "\n",
    "OHE.fit_transform(df3[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# cat_cols = []\n",
    "# num_cols = []\n",
    "\n",
    "# for i in df3.columns:\n",
    "#     if df3[i].dtype == 'object' or df3[i].dtype =='bool':\n",
    "#         cat_cols.append(i)\n",
    "#     else:\n",
    "#         num_cols.append(i)\n",
    "\n",
    "# print(cat_cols,'\\n\\n', num_cols)\n",
    "\n",
    "ColumnTransformer([('cat', OneHotEncoder(), cat_columns)]).fit_transform(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df3[cat_columns]).iloc[:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# profile = ProfileReport(df)\n",
    "# profile.to_file(output_file = 'Profile_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To veiw profile report in notebook\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = pd.DataFrame(MinMaxScaler().fit_transform(df[num_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.get_dummies(df[cat_columns]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bool = df[bool_columns].reset_index(drop = True)\n",
    "df_bool.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for machine learning\n",
    "\n",
    "df_ml = df_num.join(df_cat).join(df_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer([('num_trans', MinMaxScaler(), num_columns),\n",
    "                                        ('cat_trans', OneHotEncoder(), cat_columns)], \n",
    "                                       remainder = 'passthrough'\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = pd.DataFrame(column_transformer.fit_transform(df3))\n",
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df3.columns), df3.columns, '\\n\\n')\n",
    "print(len(df_ml.columns), df_ml.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add feature names to the transformed dataframe\n",
    "\n",
    "df_ml.columns = column_transformer.get_feature_names_out()\n",
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upscalling minority class data (default cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library package for upscalling imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imbalanced-learn==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_2 = df_ml.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ml_2.iloc[:, :-1]\n",
    "Y = df_ml_2.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import imblearn.over_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = ADASYN(sampling_strategy = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = oversample.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y.value_counts(), '\\n\\n', y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "355/434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, stratify = y, random_state = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style = 'background: Pink'> KNN model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style = 'background: Pink'> Linear regression model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross-validation and Kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(lr, x_train, y_train, cv = 5, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives prediction of each element in the input when it was in test split in cross-validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(lr, x, y, cv = 5)\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "for train_index, test_index in kfold.split(x, y):\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    lr.fit(x_train, y_train)\n",
    "    y_pred = lr.predict(x_test)\n",
    "    print(confusion_matrix(y_test, y_pred), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn. model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters tuning\n",
    "\n",
    "params = {'n_neighbors': [2, 3, 4, 5, 6, 7, 8]}\n",
    "          \n",
    "clf = GridSearchCV(KNeighborsClassifier(), param_grid = params, \n",
    "                   cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 6), \n",
    "                   scoring = 'f1')\n",
    "          \n",
    "clf.fit(x_train, y_train)\n",
    "          \n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = 'background: Yellow'> Defining function for model training with GridSearchCV </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml(model, folds, params = {}):\n",
    "    \n",
    "    global clf\n",
    "    \n",
    "    clf = GridSearchCV(model, param_grid = params, \n",
    "                       cv = StratifiedKFold(n_splits = folds, shuffle = True, random_state = 6),\n",
    "                       scoring = 'f1')\n",
    "    \n",
    "    clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml(LogisticRegression(),5)                       \n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <span style = 'background: Pink'> Random Forest model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': [10, 20, 25, 30, 35, 40],\n",
    "          'criterion': ['gini', 'entropy']}\n",
    "\n",
    "ml(RandomForestClassifier(), 3, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(criterion = 'gini', max_depth = 25)\n",
    "clf2.fit(x_train, y_train)\n",
    "y_pred = clf2.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Threshold tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Probability for the predicting each instance as 1\n",
    "\n",
    "pred_prob_fr_posit = lr.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC_AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, pred_prob_fr_posit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_test, pred_prob_fr_posit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = tpr\n",
    "specivity = 1- fpr\n",
    "\n",
    "gmean = (sensitivity*specivity)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold[gmean.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot(fpr[gmean.argmax()], tpr[gmean.argmax()], marker = 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youden's J statistics\n",
    "\n",
    "Y_stat = tpr-fpr\n",
    "threshold[Y_stat.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.plot(fpr[Y_stat.argmax()], tpr[Y_stat.argmax()], marker = 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision- Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(y_test, pred_prob_fr_posit)\n",
    "\n",
    "fscore = 2*precision*recall/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(precision, recall)\n",
    "plt.plot(precision[fscore.argmax()], recall[fscore.argmax()], marker = 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking scores at different thresolds for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "threshold = np.arange(0, 1.1, 0.1)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# To check score on different thresholds\n",
    "# lr.predict_proba(x_test)[:, 1] >= i).astype('int')\n",
    "\n",
    "for i in threshold:\n",
    "    print(confusion_matrix(y_test, (lr.predict_proba(x_test)[:, 1] >= i).astype('int')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = 'background: Pink'> XGboost model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style = 'background: Yellow'> Running different models with default parameters on the training set </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier(), XGBClassifier()]:\n",
    "    i.fit(x_train, y_train)\n",
    "    y_pred = i.predict(x_test)\n",
    "    print(f1_score(y_test, y_pred), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV on XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "params = {'max_depth': [4, 5, 6, 7, 8],\n",
    "         'learning_rate': [0.05, 0.01, 0.1],\n",
    "         'gamma': [0, 0.25, 1],\n",
    "         'reg_lambda': [0, 1, 10],\n",
    "         'subsample': [0.5, 0.75, 1],\n",
    "         'colsample_bytree': [0.5, 0.75, 1]}\n",
    "\n",
    "ml(XGBClassifier(), 4, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = 'background: Red'> Training final/best model from GridSearchCV </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth = 7, colsample_bytree = 1, gamma = 0.25, learning_rate = 0.1, reg_lambda = 1, subsample = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(x_train, y_train)\n",
    "y_pred = xgb.predict(x_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier(max_depth = 7)\n",
    "# xgb.fit(x_train, y_train)\n",
    "\n",
    "# To check score on different thresholds\n",
    "threshold = np.arange(0.1, 0.9, 0.1)\n",
    "\n",
    "for i in threshold:\n",
    "    print(f1_score(y_test, (xgb.predict_proba(x_test)[:, 1] >= i).astype('int')), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"xgb.pkl\", mode = 'wb')\n",
    "\n",
    "pickle.dump(xgb, pickle_out)\n",
    "\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
